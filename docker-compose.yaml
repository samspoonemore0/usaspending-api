version: '3.7'

volumes:
  local_pg_data:
    driver: local
  local_es_data:
    driver: local

# See run instructions in accompanying Dockerfile
services:

  usaspending-db:
    container_name: usaspending-db
    image: postgres:10.13-alpine
    volumes:
      - type: volume
        source: local_pg_data
        target: /var/lib/postgresql/data
    ports:
      - ${POSTGRES_PORT}:5432
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: data_store_api

  usaspending-manage:
    build: .
    volumes:
     - .:/dockermount
    depends_on:
      - usaspending-db
    command: python3 -u manage.py shell
    environment:
      DJANGO_DEBUG: ${DJANGO_DEBUG}
      DATABASE_URL: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/data_store_api
      ES_HOSTNAME: ${ES_HOST}:${ES_PORT}
      DATA_BROKER_DATABASE_URL: postgresql://${BROKER_USER}:${BROKER_PASSWORD}@${BROKER_HOST}:${BROKER_PORT}/data_broker

  usaspending-test:
    build: .
    volumes:
     - .:/dockermount
     # Required to interact with host's docker daemon from within this running container,
     # to spin up the data-act-broker-init-test-db container used for broker integration tests (see: conftest.broker_db_setup)
     - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - usaspending-db
      - usaspending-es
    command: pytest
    environment:
      DATABASE_URL: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/data_store_api
      ES_HOSTNAME: ${ES_HOST}:${ES_PORT}
      DATA_BROKER_DATABASE_URL: postgresql://${BROKER_USER}:${BROKER_PASSWORD}@${BROKER_HOST}:${BROKER_PORT}/data_broker
      # Location in host machine where broker src code root can be found
      DATA_BROKER_SRC_PATH: "$PWD/../data-act-broker-backend"

  usaspending-ci:
    build: .
    volumes:
     - .:/dockermount
     # Required to interact with host's docker daemon from within this running container,
     # to spin up the data-act-broker-init-test-db container used for broker integration tests (see: conftest.broker_db_setup)
     - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - usaspending-db
      - usaspending-es
    command:
      - sh
      - -c
      - |
        printf "==============\nChecking code format:\n"
        black --check --diff .
        printf -- "-------\nChecking code syntax:\n"
        flake8 && echo "Successfully passed"
        printf -- "-------\nChecking API documentation files:\n"
        python3 manage.py check_for_endpoint_documentation
        printf -- "-------\nRunning unit tests:\n"
        pytest --durations 50 --ignore-glob='**/tests/integration/*' --cov=usaspending_api --cov-report= --reuse-db -rsx
        printf -- "-------\nRunning integration tests:\n"
        pytest --durations 50 --override-ini=python_files='**/tests/integration/*' --cov=usaspending_api --cov-append --cov-report term --cov-report xml:coverage.xml --reuse-db -rsx
    environment:
      DATABASE_URL: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/data_store_api
      ES_HOSTNAME: ${ES_HOST}:${ES_PORT}
      DATA_BROKER_DATABASE_URL: postgresql://${BROKER_USER}:${BROKER_PASSWORD}@${BROKER_HOST}:${BROKER_PORT}/data_broker
      # Location in host machine where broker src code root can be found
      DATA_BROKER_SRC_PATH: "$PWD/../data-act-broker-backend"

  usaspending-api:
    build: .
    volumes:
      - .:/dockermount
    ports:
      - 8000:8000
    depends_on:
      - usaspending-db
      - usaspending-es
    restart: on-failure:3 # 3 max attempt, and then it will stop restarting
    # Must wait on postgres db to be up (~9s)
    command: /bin/sh -c "sleep 9s; python3 -u manage.py runserver --verbosity 2 0.0.0.0:8000"
    environment:
      DJANGO_DEBUG: ${DJANGO_DEBUG}
      RUN_LOCAL_DOWNLOAD_IN_PROCESS: "False"
      DB_SOURCE: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/data_store_api
      DB_R1: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/data_store_api
      DOWNLOAD_DATABASE_URL: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/data_store_api
      ES_HOSTNAME: ${ES_HOST}:${ES_PORT}

  usaspending-bulk-download:
    container_name: usaspending-bulk-download
    build: .
    restart: on-failure:5 # 5 max attempt, and then it will stop restarting. NOTE: bulk download errors will cause one failure+restart iterations
    volumes:
    - .:/dockermount
    command: python3 manage.py download_sqs_worker
    environment:
      DJANGO_DEBUG: ${DJANGO_DEBUG}
      DATABASE_URL: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/data_store_api
      DOWNLOAD_DATABASE_URL: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/data_store_api

  usaspending-es:
      container_name: usaspending-es
      image: docker.elastic.co/elasticsearch/elasticsearch:7.1.1
      environment:
        - node.name=usaspending-es
        - discovery.seed_hosts=usaspending-es
        - cluster.initial_master_nodes=usaspending-es
        - cluster.name=usaspending
        - network.host=0.0.0.0
        - bootstrap.memory_lock=true
        - "ES_JAVA_OPTS=-Xms1536m -Xmx1536m"  # Ensure Docker is allocated plenty of memory, otherwise this will fail
      # Inject plugin install, then resume with orignial entrypoint command
      command: >
        /bin/sh -c "
          if [ ! -d /usr/share/elasticsearch/plugins/mapper-murmur3 ]; then
            # Certificate problem workaround when on VPN - wget without checking cert, then install from local filesystem
            wget --no-check-certificate https://artifacts.elastic.co/downloads/elasticsearch-plugins/mapper-murmur3/mapper-murmur3-7.1.1.zip
            ./bin/elasticsearch-plugin install file:///usr/share/elasticsearch/mapper-murmur3-7.1.1.zip
          fi
          /usr/local/bin/docker-entrypoint.sh"
      ulimits:
        memlock:
          soft: -1
          hard: -1
      volumes:
      - type: volume
        source: local_es_data
        target: /usr/share/elasticsearch/data
      ports:
        - 9200:9200

  usaspending-kibana-es:
      container_name: usaspending-kibana-es
      image: docker.elastic.co/kibana/kibana-oss:7.1.1
      # ELASTICSEARCH_HOSTS should match the port for "usaspending-es"; value will need to be updated if using Windows
      environment:
        - ELASTICSEARCH_HOSTS="http://docker.for.mac.localhost:9200"
      ports:
        - 5601:5601
